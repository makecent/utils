# optimizer
optimizer = dict(type='Adam', lr=1e-04)
optimizer_config = dict(grad_clip=None)
# learning policy
lr_config = dict(policy='fixed')
total_epochs = 200

